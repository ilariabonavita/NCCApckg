{
    "collab_server" : "",
    "contents" : "#' Nonparametric Canonical Correlation Analysis\n#'\n#' @description Compute the Nonparametric canonical correlations between two data matrices\n#'\n#' @importFrom FNN get.knnx()\n#' @importFrom Matrix spMatrix(), Diagonal()\n#' @importFrom irlba irlba()\n#'\n#' @param X The training data set containing n samples and p features\n#' @param Y The paired training data set containing n samples and q features\n#' @param XV The validation data set containing nv samples and p features\n#' @param YV The paired validation data set containing nv samples and q features\n#' @param XT The testing data set containing nt samples and p features\n#' @param YT The paired testing data set containing nt samples and q features\n#' @param d The dimension of the ouput transformed features\n#' @param hx The bandwidth parameters for the KDEs of X\n#' @param hy The bandwidth parameters for the KDEs of Y\n#' @param nx The number of nearest neighbors for the KDEs of X\n#' @param ny The number of nearest neighbors for the KDEs of Y\n#' @param PreComputedNNs The name of the .Rda file containing two n*nx matrices for the nearest neighbor indice and the nearest neighbor Euclidean distances for X, and two n*ny matrices for the nearest neighbor indice and the nearest neighbor Euclidean distances for Y.  It is optional, only for debugging purposes.\n#' @param ...\n#'\n#' @return X_new The d-dimensional projections of the training data X\n#' @return Y_new The d-dimensional projections of the training data Y\n#' @return XV_new The d-dimensional projections of the validation data X\n#' @return YV_new The d-dimensional projections of the validation data Y\n#' @return XT_new The d-dimensional projections of the testing data X\n#' @return YT_new The d-dimensional projections of the testing data Y\n#' @return The canonical correlation between X_new and Y_new\n#' @return The canonical correlation between XV_new and YV_new\n#' @return The canonical correlation between XT_new and YT_new\n#' @return p value for X_new and V_new\n#' @return p value XV_new and YV_new\n#' @return p value XT_new and YT_new\n\n#'\n#' @export\n#' @author Meiwen Jia, \\email{meiwen_jia@psych.mpg.de} Ilaria Bonavita, \\email{ilaria_bonavita@psych.mpg.de}\n#' @references Michaeli, T., Wang, W., & Livescu, K. (2015). Nonparametric canonical correlation analysis. arXiv preprint arXiv:1511.04839.\n#' @examples\n#'\n#' N <- 10000 # Overal number of examples (train+test)\n#' N_paired <- 5000 # Number of training examples\n#' MaxAngle <- 4*pi\n#' MinRadius <-0.3\n#' MaxRadius <- 8\n#' NumNNs_X <- 20\n#' NumNNs_Y <- 20\n#' sx <- 0.5\n#' sy <- 0.5\n#' set.seed(8409)\n#' ## Generate data for views 1,2\n#' t <- seq(0, MaxAngle, length.out = N)\n#' r <- seq(MinRadius, MaxRadius, length.out = N) + 2*runif(N)\n#' #### generate X, the noise can be added!\n#' X <- cbind(r*cos(t+0*rnorm(N)*0.05), r*sin(t+0*rnorm(N)*0.05))\n#' X <- X + 0*matrix(rnorm(N*2), ncol = 2)\n#' #### generate Y, the noise can be added!\n#' Y <- cbind(t+0*rnorm(N)*1, 2*rnorm(N))\n#' Y <- Y + 0*cbind(rep(0, N), rnorm(N))\n#' ## Training data\n#' PairedIndices <- sample(1:N, N_paired)\n#' ## Test (or validation) data\n#' UnpairedIndices <- setdiff(1:N,PairedIndices)\n#' ncca_res <- ncca(X[PairedIndices,],Y[PairedIndices,], X[UnpairedIndices,],Y[UnpairedIndices,],\n#'                  d = 2, hx = 0.75, hy = 0.75, nx = NumNNs_X, ny=NumNNs_Y)\n#' cat(\"The nonparametric canonical correlation between X and Y is \", ncca_res$cor_XY, \"\\n\")\n#'\nncca.rsvd <- function(X, # the paried training examples (rows) of features (columns)\n                 Y, # the paried training examples (rows) of features (columns)\n                 XV = NULL, # the paried validation examples\n                 YV = NULL, # the paried validation examples\n                 XT = NULL, # the paried test examples\n                 YT = NULL, # the paried test examples\n                 d, # the dimension of the output transformed features\n                 hx = 1, # bandwith parameters for the KDEs of X\n                 hy = 1, # bandwith parameters for the KDEs of Y\n                 nx = 20, # number of nearest neighbours of X\n                 ny = 20, # number of nearest neighbours of Y, it causes problem when nx != ny\n                 PreComputedNNs = NULL, # only for debugging purposes\n                 verbose = getOption(\"verbose\"),\n                 ...){\n  # Create dataframe for saving times\n  #time.df <- as.data.frame(matrix(nrow = 1, ncol = 3 ))\n  #colnames(time.df) <- c('user','system','elapsed')\n  #t1 <- proc.time()\n\n\n  # ## remove the NAs in the matrices\n  if(anyNA(X)| anyNA(Y)){\n    remove.na <- unlist(apply(cbind(X,Y), 1, anyNA))\n    X <- X[!remove.na, , drop = F]\n    Y <- Y[!remove.na, , drop = F]\n    rm(remove.na)\n  }\n  if(anyNA(XV)| anyNA(YV)){\n    remove.na <- unlist(apply(cbind(XV,YV), 1, anyNA))\n    XV <- XV[!remove.na, , drop = F]\n    YV <- YV[!remove.na, , drop = F]\n    rm(remove.na)\n  }\n  if(anyNA(XT)| anyNA(YT)){\n    remove.na <- unlist(apply(cbind(XT,YT), 1, anyNA))\n    XT <- XT[!remove.na, , drop = F]\n    YT <- YT[!remove.na, , drop = F]\n    rm(remove.na)\n  }\n\n  # ## Set default values to the unspecified parameters\n  N <- nrow(X)\n  ## Normalize data, using only training portion\n  NXV <- nrow(XV); NXT <- nrow(XT);\n  X <- rbind(X, XV, XT)\n  NX <- nrow(X)\n  rm(XV); rm(XT);\n  NYV <- nrow(YV); NYT <- nrow(YT);\n  Y <- rbind(Y, YV, YT)\n  NY <- nrow(Y)\n  rm(YV); rm(YT);\n  colmeansTr <-  colMeans(X[1:N, , drop = F])\n  X <- t(t(X) - colmeansTr )\n  meanrowsum2Tr <- sqrt(mean(rowSums(X[1:N, , drop = F]^2)))\n  X <- X/meanrowsum2Tr\n  Y <- t(t(Y) - colMeans(Y[1:N, , drop = F]))\n  Y <- Y/sqrt(mean(rowSums(Y[1:N, , drop = F]^2)))\n  ## compute NNs\n  if(is.null(PreComputedNNs)){\n    X_NNs <- FNN:::get.knnx(X[1:N, ], X, k = nx)\n    idxs_X <- t(X_NNs$nn.index)\n    dists_X <- t(X_NNs$nn.dist)\n    Y_NNs <- FNN:::get.knnx(Y[1:N, ], Y, k = ny)\n    idxs_Y <- t(Y_NNs$nn.index)\n    dists_Y <- t(Y_NNs$nn.dist)\n    rm(list = c(\"X_NNs\",\"Y_NNs\", \"X\", \"Y\"))\n  }else{\n    rm(list = c(\"X\", \"Y\"))\n    load(PreComputedNNs)\n  }\n  gc()\n  ## compute weight matrices for X and Y\n  colInd <- rep(c(1:NX), each = nx)\n  Dx <- Matrix::spMatrix(nrow = N, ncol = NX, i = as.vector(idxs_X), j = colInd, x = exp(-0.5*as.numeric(dists_X)/(hx^2)))\n  Dx <- Matrix::t(Dx)\n  colInd <- rep(c(1:NY), each = nx)\n  Dy <- Matrix::spMatrix(nrow = N, ncol = NY, i = as.vector(idxs_Y), j = colInd, x = exp(-0.5*as.numeric(dists_Y)/(hx^2)))\n  ## normalize the weight matrices\n  Dx <- Matrix::Diagonal(NX, 1/Matrix::rowSums(Dx))%*%Dx\n  Dy <- Dy%*%Matrix::t(Matrix::Diagonal(NY, 1/Matrix::colSums(Dy)))\n\n  ## Doubly stochastic normalization\n  ## need some interpretation\n  S <- Dx %*% Dy\n  if(verbose) cat(\"Normalizing S to be doubly stochastic ...\\n\")\n  its <- 15 # get error in SVD when the number of iterations increasing\n  if(verbose) pb <- txtProgressBar(min = 0, max = its, style = 3)\n  for(i in 1:its){\n    S <- (NY/N) * Matrix::Diagonal(NY, 1/Matrix::rowSums(S)) %*% S\n    S <- S %*% Matrix::Diagonal(NX, 1/Matrix::colSums(S)) * (NX/N)\n    if(verbose) setTxtProgressBar(pb, i)\n  }\n  if(verbose) close(pb)\n  ## compute projections using the eigendecomposition of the kernel\n  if(verbose) cat('Performing exact SVD ...\\n')\n\n  #S_SVD <- svd(S, d+1, d+1)\n  #S_SVD <- irlba::irlba(S, d+1,fastpath = F) # a fast svd on a sparse matrix\n\n  S_SVD <- rsvd::rsvd(S,d+1)\n\n  X_proj <- S_SVD$u[,2:(d+1)] * sqrt(NX)\n  Y_proj <- S_SVD$v[,2:(d+1)] * sqrt(NY)\n  ## output\n  X_new <- X_proj[1:N, ]\n  Y_new <- Y_proj[1:N, ]\n  cor_XY <- cancor(X_new, Y_new)$cor\n  #### add p-value (Ilaria)\n  p_XY <- CCP::p.asym(cor_XY, N, ncol(X_new), ncol(Y_new))\n\n  if(is.null(NXV) | is.null(NYV)){\n    XV_new <- YV_new <- cor_XVYV <- p_XVYV <- NULL\n  }else{\n    XV_new <- X_proj[N+(1:NXV), ]\n    YV_new <- Y_proj[N+(1:NYV), ]\n    cor_XVYV <- cancor(XV_new, YV_new)$cor\n    #### add p-value\n    p_XVYV <- CCP::p.asym(cor_XVYV, NXV, ncol(XV_new), ncol(YV_new))\n  }\n  if(is.null(NXT) | is.null(NYT)){\n    XT_new <- YT_new <- cor_XTYT <- p_XTYT <- NULL\n  }else{\n    XT_new <- X_proj[(N+NXV+1):NX, ]\n    YT_new <- Y_proj[(N+NYV+1):NY, ]\n    cor_XTYT <- cancor(XT_new, YT_new)$cor\n    #### add p-value\n    p_XTYT <- CCP::p.asym(cor_XTYT, NXT, ncol(XT_new), ncol(YT_new))\n  }\n # time.df[1, ]<- (proc.time()- t1)[1:3]\n#  write.table(time.df,paste0(snp.dir,'/time.single_',svd.alg),append=T)\n  ncca_out <- list(colmeanX=colmeansTr, meanrowsumX=meanrowsum2Tr, Wx=Dx, Wy=Dy, X_new = X_new, Y_new = Y_new,\n                   XV_new = XV_new, YV_new = YV_new,\n                   XT_new = XT_new, YT_new = YT_new,\n                   cor_XY = cor_XY, cor_XVYV = cor_XVYV, cor_XTYT = cor_XTYT, p_XY=p_XY, p_XVYV=p_XVYV, p_XTYT=p_XTYT)\n  return(ncca_out)\n}\n",
    "created" : 1530179687125.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2506638325",
    "id" : "1A4BC85B",
    "lastKnownWriteTime" : 1530181895,
    "last_content_update" : 1530181895085,
    "path" : "~/My_project/NCCA/R/ncca.rsvd.R",
    "project_path" : "R/ncca.rsvd.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}